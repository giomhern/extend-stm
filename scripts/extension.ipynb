{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8e6c827",
   "metadata": {},
   "source": [
    "## Extension: BERTopic \n",
    "\n",
    "This jupyter file follows as we attempt to do a comparative analysis between STM and a modern framework, namely BERTopic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "49890739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ab95a1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/Users/giomhern/04 Projects/topic-models/data\"\n",
    "df = pd.read_csv(f\"{DATA_DIR}/gadarian_bertopic_input.csv\")\n",
    "texts = df[\"open.ended.response\"].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "139a273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric=\"cosine\", random_state=42)\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "kmeans_model = KMeans(n_clusters=3, random_state=42)\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    umap_model=umap_model,\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    hdbscan_model = kmeans_model, \n",
    "    calculate_probabilities=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "1f41cff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-29 19:28:56,609 - BERTopic - Embedding - Transforming documents to embeddings.\n",
      "Batches: 100%|██████████| 11/11 [00:00<00:00, 40.16it/s]\n",
      "2025-05-29 19:28:56,889 - BERTopic - Embedding - Completed ✓\n",
      "2025-05-29 19:28:56,890 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-05-29 19:28:57,185 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-05-29 19:28:57,185 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "/opt/anaconda3/envs/models/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in matmul\n",
      "\n",
      "/opt/anaconda3/envs/models/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning:\n",
      "\n",
      "overflow encountered in matmul\n",
      "\n",
      "/opt/anaconda3/envs/models/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in matmul\n",
      "\n",
      "2025-05-29 19:28:57,195 - BERTopic - Cluster - Completed ✓\n",
      "2025-05-29 19:28:57,198 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2025-05-29 19:28:57,208 - BERTopic - Representation - Completed ✓\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Topic 0 ---\n",
      "jobs            0.10629\n",
      "people          0.06557\n",
      "illegal         0.06493\n",
      "americans       0.06314\n",
      "welfare         0.06115\n",
      "care            0.05780\n",
      "taxes           0.04862\n",
      "security        0.04679\n",
      "social          0.04641\n",
      "immigrants      0.04515\n",
      "\n",
      "--- Topic 1 ---\n",
      "illegal         0.10536\n",
      "people          0.09744\n",
      "immigrants      0.08177\n",
      "country         0.07615\n",
      "mexico          0.06034\n",
      "border          0.05925\n",
      "coming          0.05522\n",
      "legal           0.04923\n",
      "entering        0.04482\n",
      "english         0.03863\n",
      "\n",
      "--- Topic 2 ---\n",
      "immigration     0.09282\n",
      "think           0.09010\n",
      "immigrants      0.07798\n",
      "people          0.06006\n",
      "country         0.05926\n",
      "need            0.05137\n",
      "legally         0.04147\n",
      "illegal         0.04138\n",
      "worry           0.04075\n",
      "come            0.03783\n"
     ]
    }
   ],
   "source": [
    "topics, _ = topic_model.fit_transform(texts)\n",
    "\n",
    "# Show top 15 words for each topic\n",
    "for topic_idx in topic_model.get_topics().keys():\n",
    "    print(f\"\\n--- Topic {topic_idx} ---\")\n",
    "    for word, weight in topic_model.get_topic(topic_idx)[:15]:\n",
    "        print(f\"{word:<15} {weight:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "6b4c289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bertopic_top_words.txt\", \"w\") as f:\n",
    "    for topic_idx in topic_model.get_topics().keys():\n",
    "        if topic_idx == -1:\n",
    "            continue  # Skip outlier topic if present\n",
    "        f.write(f\"--- Topic {topic_idx} ---\\n\")\n",
    "        top_words = topic_model.get_topic(topic_idx)[:15]\n",
    "        for word, weight in top_words:\n",
    "            f.write(f\"{word:<15} {weight:.5f}\\n\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "a33d40bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"topic\"] = topics\n",
    "\n",
    "topic_labels = {\n",
    "    0: \"Economic Costs\",\n",
    "    1: \"Border Control\",\n",
    "    2: \"Moral Reasoning\"\n",
    "}\n",
    "df[\"topic_label\"] = df[\"topic\"].map(topic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "69051226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Setup: classify Topic 1\n",
    "df[\"is_topic_1\"] = (df[\"topic\"] == 0).astype(int)  # Adjust if needed\n",
    "\n",
    "# Center pid_rep\n",
    "df[\"pid_centered\"] = df[\"pid_rep\"] - df[\"pid_rep\"].mean()\n",
    "df[\"interaction\"] = df[\"pid_centered\"] * df[\"treatment\"]\n",
    "\n",
    "# Fit logistic model with interaction\n",
    "X = sm.add_constant(df[[\"treatment\", \"pid_centered\", \"interaction\"]])\n",
    "y = df[\"is_topic_1\"]\n",
    "model = sm.Logit(y, X).fit(disp=0)\n",
    "\n",
    "# Prediction grid\n",
    "pid_vals = np.linspace(df[\"pid_rep\"].min(), df[\"pid_rep\"].max(), 100)\n",
    "grid = []\n",
    "for t in [0, 1]:\n",
    "    for pid in pid_vals:\n",
    "        centered = pid - df[\"pid_rep\"].mean()\n",
    "        grid.append({\n",
    "            \"const\": 1,\n",
    "            \"treatment\": t,\n",
    "            \"pid_centered\": centered,\n",
    "            \"interaction\": centered * t,\n",
    "            \"pid_rep\": pid,\n",
    "            \"label\": \"Treated\" if t == 1 else \"Control\"\n",
    "        })\n",
    "\n",
    "pred_df = pd.DataFrame(grid)\n",
    "pred_X = pred_df[[\"const\", \"treatment\", \"pid_centered\", \"interaction\"]]\n",
    "\n",
    "# Predict with confidence intervals\n",
    "pred = model.get_prediction(pred_X).summary_frame(alpha=0.05)\n",
    "pred_df[\"predicted\"] = pred[\"predicted\"]\n",
    "pred_df[\"lower\"] = pred[\"ci_lower\"]\n",
    "pred_df[\"upper\"] = pred[\"ci_upper\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "93780d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "\n",
    "for label, color in zip([\"Control\", \"Treated\"], [\"blue\", \"red\"]):\n",
    "    subset = pred_df[pred_df[\"label\"] == label]\n",
    "    plt.plot(subset[\"pid_rep\"], subset[\"predicted\"], color=color, label=label)\n",
    "    plt.fill_between(subset[\"pid_rep\"], subset[\"lower\"], subset[\"upper\"], color=color, alpha=0.2)\n",
    "\n",
    "# Custom x-axis ticks\n",
    "plt.xticks(\n",
    "    [df[\"pid_rep\"].min(), df[\"pid_rep\"].mean(), df[\"pid_rep\"].max()],\n",
    "    labels=[\"Strong Democrat\", \"Moderate\", \"Strong Republican\"]\n",
    ")\n",
    "\n",
    "# Remove x-axis label and title\n",
    "plt.xlabel(\"\")\n",
    "plt.title(\"\")\n",
    "\n",
    "# Y-axis label and limits\n",
    "plt.ylabel(\"Predicted Probability\")\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Black plot frame\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_edgecolor(\"black\")\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Save to file\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/Users/giomhern/04 Projects/topic-models/output/gadarian/bert_border_control_minimal.pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57207d25",
   "metadata": {},
   "source": [
    "## ANES Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "123c47d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{DATA_DIR}/final_anes_metadata.csv\")\n",
    "df[\"text\"] = df[[\"mii_1\", \"mii_2\"]].fillna(\"\").agg(\" \".join, axis=1).str.strip()\n",
    "df = df[\n",
    "    (df[\"pid_summary\"] > 0) &\n",
    "    (df[\"highest grade completed\"] > 0) &\n",
    "    (df[\"age\"] > 0) &\n",
    "    (df[\"text\"] != \"\") &\n",
    "    df[\"female\"].notna()\n",
    "].copy()\n",
    "\n",
    "# Extract text and covariates\n",
    "texts = df[\"text\"].tolist()\n",
    "covariates = df[[\"pid_summary\", \"age\", \"highest grade completed\", \"female\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "fb7fa5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-29 20:00:31,494 - BERTopic - Embedding - Transforming documents to embeddings.\n",
      "Batches: 100%|██████████| 47/47 [00:00<00:00, 79.44it/s]\n",
      "2025-05-29 20:00:32,093 - BERTopic - Embedding - Completed ✓\n",
      "2025-05-29 20:00:32,093 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-05-29 20:00:34,097 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-05-29 20:00:34,098 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "/opt/anaconda3/envs/models/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in matmul\n",
      "\n",
      "/opt/anaconda3/envs/models/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning:\n",
      "\n",
      "overflow encountered in matmul\n",
      "\n",
      "/opt/anaconda3/envs/models/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in matmul\n",
      "\n",
      "2025-05-29 20:00:34,103 - BERTopic - Cluster - Completed ✓\n",
      "2025-05-29 20:00:34,104 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2025-05-29 20:00:34,114 - BERTopic - Representation - Completed ✓\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Setup components\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric=\"cosine\", random_state=42)\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "kmeans_model = KMeans(n_clusters=10, random_state=42)\n",
    "\n",
    "# Fit BERTopic model\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    umap_model=umap_model,\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    hdbscan_model=kmeans_model,\n",
    "    calculate_probabilities=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "topics = topic_model.fit_transform(texts)[0]\n",
    "df[\"topic\"] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "d69bce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"top_bertopic_words.txt\", \"w\") as f:\n",
    "    for topic_num in topic_model.get_topic_info().head(10)[\"Topic\"]:\n",
    "        if topic_num == -1:\n",
    "            continue  # skip outliers\n",
    "        f.write(f\"\\n--- Topic {topic_num} ---\\n\")\n",
    "        for word, weight in topic_model.get_topic(topic_num)[:15]:\n",
    "            f.write(f\"{word:<15} {weight:.5f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "fad32b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Select topic\n",
    "target_topic = 5  # adjust as needed\n",
    "df[\"is_topic\"] = (df[\"topic\"] == target_topic).astype(int)\n",
    "\n",
    "# Party dummy: 0 = Democrat (pid < 4), 1 = Republican (pid >= 4)\n",
    "df[\"is_republican\"] = (df[\"pid_summary\"] >= 4).astype(int)\n",
    "\n",
    "# Center education\n",
    "df[\"edu_centered\"] = df[\"highest grade completed\"] - df[\"highest grade completed\"].mean()\n",
    "\n",
    "# Interaction term\n",
    "df[\"interaction\"] = df[\"edu_centered\"] * df[\"is_republican\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "e43cb07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(df[[\"edu_centered\", \"is_republican\", \"interaction\"]])\n",
    "y = df[\"is_topic\"]\n",
    "\n",
    "model = sm.Logit(y, X).fit(disp=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "aace4df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction grid\n",
    "edu_vals = np.linspace(13, 17, 100)\n",
    "grid = []\n",
    "\n",
    "for party in [0, 1]:  # 0 = Democrat, 1 = Republican\n",
    "    for edu in edu_vals:\n",
    "        edu_c = edu - df[\"highest grade completed\"].mean()\n",
    "        grid.append({\n",
    "            \"const\": 1,\n",
    "            \"edu_centered\": edu_c,\n",
    "            \"is_republican\": party,\n",
    "            \"interaction\": edu_c * party,\n",
    "            \"education\": edu,\n",
    "            \"label\": \"Republican\" if party else \"Democrat\"\n",
    "        })\n",
    "\n",
    "pred_df = pd.DataFrame(grid)\n",
    "pred_X = pred_df[[\"const\", \"edu_centered\", \"is_republican\", \"interaction\"]]\n",
    "\n",
    "# Predict with CI\n",
    "pred = model.get_prediction(pred_X).summary_frame(alpha=0.05)\n",
    "pred_df[\"predicted\"] = pred[\"predicted\"]\n",
    "pred_df[\"lower\"] = pred[\"ci_lower\"]\n",
    "pred_df[\"upper\"] = pred[\"ci_upper\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "98e9f310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "\n",
    "# Plot lines and confidence intervals\n",
    "for label, color in zip([\"Democrat\", \"Republican\"], [\"blue\", \"red\"]):\n",
    "    subset = pred_df[pred_df[\"label\"] == label]\n",
    "    plt.plot(subset[\"education\"], subset[\"predicted\"], color=color, label=label)\n",
    "    plt.fill_between(subset[\"education\"], subset[\"lower\"], subset[\"upper\"], color=color, alpha=0.2)\n",
    "\n",
    "# Customize axes\n",
    "plt.xlabel(\"\")  # Remove x-axis label\n",
    "plt.ylabel(\"Predicted Probability\")\n",
    "plt.title(\"\")   # Remove title\n",
    "plt.ylim(0, 0.4)\n",
    "\n",
    "# Add x-axis ticks for clarity if needed\n",
    "plt.xticks(\n",
    "    [13, 14, 15, 16, 17],\n",
    "    labels=[\"13\", \"14\", \"15\", \"16\", \"17\"]\n",
    ")\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Add black frame\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_edgecolor(\"black\")\n",
    "\n",
    "# Save if desired\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/Users/giomhern/04 Projects/topic-models/output/anes/topic_edu_party.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb6c846",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
